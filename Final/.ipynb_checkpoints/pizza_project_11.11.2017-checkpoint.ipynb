{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Julia sample code\n",
    "using DataFrames\n",
    "using MachineLearning\n",
    "using JSON\n",
    "\n",
    "function read_data(file_name)\n",
    "    f = open(file_name)\n",
    "    json = JSON.parse(readall(f))\n",
    "    close(f)\n",
    "\n",
    "    colnames = keys(json[1])\n",
    "    columns  = Any[[json[i][name] for i=1:length(json)] for name=colnames]\n",
    "    DataFrame(columns, Symbol[name for name=colnames])\n",
    "end\n",
    "\n",
    "train = read_data(\"../data/train.json\")\n",
    "test  = read_data(\"../data/test.json\")\n",
    "\n",
    "println(@sprintf(\"There are %d rows in the training set\", nrow(train)))\n",
    "println(@sprintf(\"There are %d rows in the test set\", nrow(test)))\n",
    "\n",
    "feature_names = Symbol[\"requester_account_age_in_days_at_request\",\n",
    "                       \"requester_days_since_first_post_on_raop_at_request\",\n",
    "                       \"requester_number_of_comments_at_request\",\n",
    "                       \"requester_number_of_comments_in_raop_at_request\",\n",
    "                       \"requester_number_of_posts_at_request\",\n",
    "                       \"requester_number_of_posts_on_raop_at_request\",\n",
    "                       \"requester_number_of_subreddits_at_request\",\n",
    "                       \"requester_upvotes_minus_downvotes_at_request\",\n",
    "                       \"requester_upvotes_plus_downvotes_at_request\",\n",
    "                       \"unix_timestamp_of_request_utc\"]\n",
    "\n",
    "for feature = feature_names\n",
    "    train[feature] = float64(train[feature])\n",
    "    test[feature]  = float64(test[feature])\n",
    "end\n",
    "\n",
    "columns_to_keep = cat(1, feature_names, [:requester_received_pizza])\n",
    "\n",
    "rf = fit(train[columns_to_keep], :requester_received_pizza, classification_forest_options(num_trees=200, display=true))\n",
    "println(\"\")\n",
    "println(rf)\n",
    "println(\"\")\n",
    "predictions = predict_probs(rf, test)[:,2]\n",
    "submission = DataFrame(request_id=test[:request_id], requester_received_pizza=predictions)\n",
    "writetable(\"simple_julia_benchmark.csv\", submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 4040\n",
      "Test len: 1631\n",
      "<class 'dict'>\n",
      "Train example:\n",
      " {'requester_number_of_posts_at_retrieval': 1, 'requester_upvotes_minus_downvotes_at_retrieval': 3, 'unix_timestamp_of_request': 1319650094.0, 'number_of_downvotes_of_request_at_retrieval': 0, 'requester_upvotes_plus_downvotes_at_retrieval': 3, 'giver_username_if_known': 'N/A', 'requester_days_since_first_post_on_raop_at_retrieval': 771.6161805555555, 'requester_number_of_comments_in_raop_at_request': 0, 'requester_user_flair': None, 'request_text_edit_aware': \"My girlfriend decided it would be a good idea to get off at Perth bus station when she was coming to visit me and has since had to spend all her money on a taxi to get to me here in Dundee. Any chance some kind soul would get us some pizza since we don't have any cash anymore?\", 'requester_account_age_in_days_at_request': 0.0, 'request_id': 't3_lpu5j', 'requester_received_pizza': False, 'requester_number_of_comments_in_raop_at_retrieval': 0, 'unix_timestamp_of_request_utc': 1319646494.0, 'requester_username': 'jacquibatman7', 'request_title': '[Request] Hungry couple in Dundee, Scotland would love some pizza!', 'requester_account_age_in_days_at_retrieval': 771.6161805555555, 'post_was_edited': False, 'request_number_of_comments_at_retrieval': 0, 'requester_number_of_posts_on_raop_at_retrieval': 1, 'requester_number_of_posts_on_raop_at_request': 0, 'requester_subreddits_at_request': [], 'requester_number_of_subreddits_at_request': 0, 'requester_number_of_comments_at_retrieval': 0, 'requester_days_since_first_post_on_raop_at_request': 0.0, 'request_text': \"My girlfriend decided it would be a good idea to get off at Perth bus station when she was coming to visit me and has since had to spend all her money on a taxi to get to me here in Dundee. Any chance some kind soul would get us some pizza since we don't have any cash anymore?\", 'requester_number_of_comments_at_request': 0, 'number_of_upvotes_of_request_at_retrieval': 3, 'requester_upvotes_plus_downvotes_at_request': 0, 'requester_number_of_posts_at_request': 0, 'requester_upvotes_minus_downvotes_at_request': 0}\n",
      "Test example:\n",
      " {'requester_number_of_subreddits_at_request': 1, 'unix_timestamp_of_request_utc': 1377929522.0, 'unix_timestamp_of_request': 1377933122.0, 'requester_number_of_comments_at_request': 1, 'requester_subreddits_at_request': ['IAmA'], 'giver_username_if_known': 'N/A', 'requester_number_of_comments_in_raop_at_request': 0, 'request_text_edit_aware': \"My SO and I are moving to the new apartment tomorrow which has put us in the poor house (paid first and last months rent upfront) so we currently have a combined total of $0.65\\n\\nWe've been frugal with food, meaning lots of rice and KD, but our dishes / food are packed up and my midnight prego cravings have hit hard. \\n\\nAnd Pizza Pizza closes in an hour. D:\\n\\nAnyone care to donate a pepperoni pizza? Pretty please!\", 'requester_days_since_first_post_on_raop_at_request': 0.0, 'requester_account_age_in_days_at_request': 43.332118055555554, 'requester_number_of_posts_on_raop_at_request': 0, 'request_id': 't3_1lg6u2', 'requester_username': 'RosyGraymalkin', 'requester_upvotes_plus_downvotes_at_request': 6, 'requester_number_of_posts_at_request': 0, 'request_title': '[Request] Pregnant, packing @ 2am to move tomorrow and poor! Pity pizza?', 'requester_upvotes_minus_downvotes_at_request': 0}\n"
     ]
    }
   ],
   "source": [
    "#json libraries\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load Data\n",
    "train_data = json.load(open(\"../data/train.json\"))\n",
    "print(\"Train len:\",len(train_data))\n",
    "test_data = json.load(open(\"../data/test.json\"))\n",
    "print(\"Test len:\",len(test_data))\n",
    "print(type(train_data[0]))\n",
    "print(\"Train example:\\n\",train_data[2])\n",
    "print(\"Test example:\\n\",test_data[8])\n",
    "\n",
    "# split train set into train and development for initial testing before submitting final predictions on test.json\n",
    "\n",
    "# DATA SUMMARY:\n",
    "# list of dictionaries\n",
    "# 'request_id' - sample point identifier, for final submission\n",
    "# 'requester_received_pizza' - boolean True, False\n",
    "# 'request_text' - raw text request, not always populated\n",
    "# 'request_text_edit_aware' - with \"edit\" comment removed, e.g. \"thanks for pizza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040 4040\n",
      "['Hi I am in need of food for my 4 children we are a military family that has really hit hard times and we have exahusted all means of help just to be able to feed my family and make it through another night is all i ask i know our blessing is coming so whatever u can find in your heart to give is greatly appreciated', 'I spent the last money I had on gas today. Im broke until next Thursday :('] \n",
      " [False, False]\n",
      "1631\n"
     ]
    }
   ],
   "source": [
    "# pull raw text and labels from train and test\n",
    "train_raw_text_list = []\n",
    "train_labels = []\n",
    "\n",
    "test_raw_text_list = []\n",
    "\n",
    "for ob in train_data:\n",
    "    #print(type(ob))\n",
    "    train_raw_text_list.append(ob['request_text_edit_aware'])\n",
    "    train_labels.append(ob['requester_received_pizza'])\n",
    "print(len(train_raw_text_list), len(train_labels))\n",
    "print(train_raw_text_list[0:2], \"\\n\", train_labels[0:2])\n",
    "\n",
    "for ob in test_data:\n",
    "    test_raw_text_list.append(ob['request_text_edit_aware'])\n",
    "print(len(test_raw_text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(obs, features): (4040, 12317)\n",
      "Training set F1 score: 0.7656\n",
      "(1631,)\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True False False False False False False False False  True  True\n",
      " False False False  True False  True False False False  True False False\n",
      " False False]\n"
     ]
    }
   ],
   "source": [
    "#vectorize\n",
    "\n",
    "#preprocess\n",
    "def preprocessor(s):\n",
    "    s = s.lower()\n",
    "    return s\n",
    "\n",
    "#vectorize text\n",
    "vectorizer = CountVectorizer(preprocessor = preprocessor)\n",
    "train_text_feats = vectorizer.fit_transform(train_raw_text_list)\n",
    "print(\"(obs, features):\", train_text_feats.shape)\n",
    "\n",
    "#train Naive Bayes classifier\n",
    "nb = BernoulliNB()\n",
    "nb.fit(train_text_feats, train_labels)\n",
    "nb_train_preds = nb.predict(train_text_feats)\n",
    "train_f1_score = metrics.f1_score(train_labels, nb_train_preds, average='micro')\n",
    "print(\"Training set F1 score:\", \"{:.4}\".format(train_f1_score))\n",
    "\n",
    "#predict on test dataset\n",
    "test_feats = vectorizer.transform(test_raw_text_list)\n",
    "nb_test_preds = nb.predict(test_feats)\n",
    "print(nb_test_preds.shape)\n",
    "print(nb_test_preds[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
